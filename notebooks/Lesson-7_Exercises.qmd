---
title: "Tema 7: PEC"
format:
  html:
    code-copy:       true
    code-tools:      true
    df-print:        paged
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
bibliography:        ../www/abd.bib
csl:                 ../www/apa-old-doi-prefix.csl
callout-appearance: minimal
---

# Introducción

En este tema hemos estudiado cómo obtener muestreas "identicamente distribuidas" (¡pero no necesariamente independientes!) de **cualquier distribución de probabilidad** gracias a la familia de algoritmos **Markov chain Monte Carlo** (MCMC).

Además, hemos aprendido acerca de la **dependencia serial** en las cadenas de Markov, cómo diagnosticarla, y su efecto en el **tamaño muestral efectivo de Monte Carlo**.

Estos ejercicios ponen en práctica estos conceptos con modelos de las lecturas, para afianzar estos conceptos.
En el [Ejercicio 1](#ejercicio-1) nos basaremos en el ejemplo del muestreador de Gibbs de @hoff2009a [pp. 98-103] para demostrar la lógica de ese algoritmo, así como las propiedades de una cadenas de Markov generada mediante el método de MCMC.

En el [Ejercicio 2](#ejercicio-2) tomaremos contacto con el software de análisis Bayesiano de datos [Stan](https://mc-stan.org/), utilizando un ejemplo del [texto de ampliación](https://agora.uned.es/mod/resource/view.php?id=514493) [@geyer2011, pp. 30-34].
Te recomiendo por tanto:

-   Realizar el [Ejercicio 1](#ejercicio-1) en primer lugar.

-   Leer a continuación el epígrafe 1.13 (A Metropolis Example) del [texto de ampliación](https://agora.uned.es/mod/resource/view.php?id=514493) [@geyer2011, pp. 30-34].

-   Por último, realizar el [Ejercicio 2](#ejercicio-2).

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)
library(scales)
library(rstan) # Nuevo paquete para el ejercicio 2 (añadir al entorno!)

# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto <- PALETA[1]      # Color por defecto
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica

# Redondea los números reales "inline":
options(digits = 3L)                
options(knitr.digits.signif = FALSE)

# Inicializa la semilla aleatoria:
set.seed(20250408)
```

Inicializamos el entorno como es habitual.
Al igual que en el ejercicio anterior, en este caso **también inicializamos la semilla aleatoria** para asegurar la **reproducibilidad**.

# Ejercicio 1: Cadena de Markov mediante muestreo de Gibbs {#ejercicio-1}

## Distribuciones condicionales

En la primera de las lecturas [@hoff2009a] hemos visto cómo muestrear de distribuciones condicionales.
Vamos a utilizar el ejemplo del epígrafe 6.6 en este ejercicio (pp. 98-103) para demostrar el "muestreo de Gibbs", las propiedades de las cadenas de Markov, y la convergencia.

Recuerda que la distribución que viene definida por[^1]

[^1]: Si te estás preguntando de dónde sale una distribución así, piensa que puede tratarse de una variable en la que hay tres grupos o "clases latentes", cada uno distribuido normalmente pero con medias diferentes; a modo de ejemplo: Usando el ejercicio sobre "velocidad de lectura" en temas anteriores, podríamos tener estudiantes pertenecientes a un grupo de "desarrollo típico" y otros dos grupos con diferentes trastornos de aprendizaje, cada uno teniendo un parámetro distinto para el valor promedio en velocidad de lectura, sin que conozcamos a priori a qué grupo pertenece cada estudiante.

$$
\begin{split}
  {Pr(δ = 1), Pr(δ = 2), Pr(δ = 3)} = (.45, .10, .45) \\
  p(θ|δ) = N(θ, μ_δ, σ_δ); \quad (μ_1, μ_2, μ_3) = (−3, 0, 3); \quad σ_1^2 = σ_2^2 = σ_3^2 = 1/3
\end{split}
$$

Podemos obtener la aproximación discreta a la distribución de $θ$, como hemos hecho en temas anteriores, para usarla como referencia:

```{r distribucion-discreta}
PREC       <- 1e-3             # Precisión para la aproximación discreta
PROB_DELTA <- c(.45, .10, .45) # Probabilidades de los tres grupos
MEDIAS     <- c(-3, 0, 3)      # Medias de los tres grupos en función de "delta"
VAR        <- 1/3              # Varianza de los tres grupos

sd      <- sqrt(VAR) # Desviación estándar de cada grupo
n_desv  <- 5 # Número de "desviaciones estándar" para calcular los límites
lim_inf <- floor(  min(MEDIAS) - n_desv * sd) # Límites para aproximación
lim_sup <- ceiling(max(MEDIAS) + n_desv * sd) #   discreta (inferior y superior)

# Aproximación discreta:
densidad <- tibble(
  theta    = seq(from = lim_inf, to = lim_sup, by = PREC),
  densidad = theta |> dnorm(mean = MEDIAS[1], sd = sd) * PROB_DELTA[1] +
             theta |> dnorm(mean = MEDIAS[2], sd = sd) * PROB_DELTA[2] +
             theta |> dnorm(mean = MEDIAS[3], sd = sd) * PROB_DELTA[3]
)

# Gráfica de la aproximación discreta:
aprox_discreta_plot <- densidad |>
  ggplot(mapping = aes(x = theta, y = densidad)) +
  geom_line(colour = color_defecto) +
  labs(
    title = "Distribución de θ",
    x = "θ",
    y = "p(θ)",
  )

aprox_discreta_plot
```

Tal y como la lectura indica, en esta distribución sería muy sencillo obtener una muestra de Monte Carlo i.i.d. Así que ten en cuenta que este ejercicio tiene un **propósito ilustrativo** sobre las **propiedades del muestreador de Gibbs**, y la aproximación de Monte Carlo que resulta de la cadena de Markov generada por este algoritmo.

### Pregunta 1

-   Dado un valor de $δ$, escibe a continuación una función que devuelva una única muestra aleatoria de $θ$ (i.e., una muestra de tamaño 1) de la distribución $p(θ|δ)$. Utiliza el prototipo de la función que se da a continuación, y los objetos globales definidos en el "chunk" de código anterior sin necesidad de definirlos de nuevo (`PROB_DELTA`, `MEDIAS`, `VAR`, o `sd`, según los necesites).

::: {#respuesta-1 .callout-note}
```{r muestrear-theta}
# Argumento `delta`: Valor entero de δ para muestrear $p(θ|δ)$
muestrear_theta <- function(delta) {
  
  rnorm(1, mean = MEDIAS[delta], sd = sd)
}
```
:::

### Pregunta 2

-   Dado un valor de $θ$, escibe a continuación una función que devuelva una única muestra aleatoria de $δ$ (i.e., una muestra de tamaño 1) de la distribución $p(δ|θ)$, tal y como se indica en la ecuación de la p. 100 de @hoff2009a. Utiliza el prototipo de la función que se da a continuación, y los objetos globales definidos en el "chunk" de código anterior sin necesidad de definirlos de nuevo (`PROB_DELTA`, `MEDIAS`, `VAR`, o `sd`, según los necesites).

::: {#respuesta-2 .callout-note}
```{r muestrear-delta}
# Argumento `theta`: Valor real de θ para muestrear $p(δ|θ)$
muestrear_delta <- function(theta) {
  
  # Calculamos la densidad de θ para cada grupo δ
  likelihoods <- dnorm(theta, mean = MEDIAS, sd = sd) * PROB_DELTA
  
  # Normalizamos para obtener la distribución de probabilidad
  probabilities <- likelihoods / sum(likelihoods)
  
  # Muestreamos un valor de δ según la distribución obtenida
  sample(1:3, size = 1, prob = probabilities)
}
```
:::

## Muestreador de Gibbs

A continuación tienes una función que realiza una iteración del muestreador de Gibbs utilizando las dos funciones que acabas de escribir, devolviendo una muestra de tamaño 1 de la distribución conjunta $p(θ, δ)$.
Es decir, dado el estado actual de la cadena de Markov, la función devuelve el siguiente estado.

```{r definir-iteracion-Gibbs}
itera_Gibbs <- function(theta, delta) {
  
  # Muestra de theta:
  theta <- muestrear_theta(delta) # Observa que el valor "actual" de theta en
                                  #   realidad no se usa en esta función, pero
                                  #   lo usamos como argumento para definir el
                                  #   "estado actual completo" de la cadena.
  # Muestra de delta:
  delta <- muestrear_delta(theta)
  
  # Devuelve el nuevo estado de la cadena de Markov:
  tibble(theta = theta, delta = delta) # Usamos el tipo "tibble" para devolver a
                                       #   la vez un número real y un entero.
}
```

Ahora vamos a definir un objeto para "almacenar" los estados de la cadena de Markov.
Aunque podríamos ir "concatenando" las filas resultantes de cada estado, es mucho más eficiente (por cómo R maneja la memoria) definir un objeto de tamaño conocido e ir "rellenándolo" con los estados de la cadena.
Para ello, vamos a necesitar el número de iteraciones de la cadena, que fijaremos en 1,000, como en el ejemplo del libro.

```{r definir-cadena-Gibbs}
N_GIBBS <- 1000 # Número de iteraciones de la cadena de Markov

cadena_Gibbs <- tibble( # Objeto para almacenar los estados de la cadena
  theta = numeric(N_GIBBS),
  delta = integer(N_GIBBS)
)
```

Con los objetos anteriores, ya tenemos casi todo lo necesario para realizar el muestreo de Gibbs.
Solamente falta el estao inicial de la cadena.

### Pregunta 3

-   Define un objeto `estado_cadena` de tipo "tibble" para que contenga un estado inicial de la cadena de Markov que tenga una alta probabilidad de encontrarse en la distribución estacionaria. Para ello, selecciona un valor próximo a uno de los tres modos de la distribución de $θ$ y un valor adecuado de $δ$, justificando la elección de ambos.

::: {#respuesta-3 .callout-note}
```{r preg-3}
estado_cadena <- tibble(
  theta = 3,   # cerca de la media del grupo 3
  delta = 3    # grupo más probable junto con el 1
)
```

La elección de los parámetros iniciales theta = 3 y delta = 3 se fundamenta en la estructura de la distribución conjunta p(theta, delta). Al comenzar en uno de los modos de la distribución, específicamente en mu_3 = 3, garantizamos que la cadena de Markov inicia en un valor con alta densidad de probabilidad, lo que facilita una rápida convergencia hacia la distribución estacionaria. Además, la selección de delta = 3 está respaldada por su probabilidad relativamente alta ( p(delta = 3) = 0.45), lo que minimiza la posibilidad de comenzar en un estado atípico o de baja frecuencia. Este punto de partida no solo asegura estabilidad en las primeras iteraciones del muestreador de Gibbs, sino que también favorece una exploración eficiente del espacio paramétrico en relación con los otros posibles valores de delta.

:::

### Pregunta 4

-   Escribe el código necesario para iterar la cadena de Markov, comenzando en el valor definido anteriormente de `estado_cadena`, y guardando los estados en el objeto `cadena_Gibbs`.

::: {#respuesta-4 .callout-note}
```{r preg-4}
# Inicializamos el primer estado
cadena_Gibbs[1, ] <- estado_cadena

# Iteramos la cadena de Markov
for (i in 2:N_GIBBS) {
  cadena_Gibbs[i, ] <- itera_Gibbs(cadena_Gibbs$theta[i - 1], cadena_Gibbs$delta[i - 1])
}

```

:::

### Pregunta 5

-   Representa la densidad de la distribución de $θ$ obtenida a partir de la cadena de Markov junto con la aproximación discreta que obtuvimos antes. Explica qué observas en el resultado.

::: {#respuesta-5 .callout-note}
```{r preg-5}
# Estimación de la densidad a partir de la cadena de Gibbs
densidad_cadena <- density(cadena_Gibbs$theta)

# Gráfica de la comparación
comparacion_plot <- ggplot() +
  geom_line(data = densidad, aes(x = theta, y = densidad), color = "blue", linetype = "dashed") + 
  geom_line(mapping = aes(x = densidad_cadena$x, y = densidad_cadena$y), color = "red") +
  labs(
    title = "Comparación de la distribución estimada y la aproximación discreta",
    x = "θ",
    y = "Densidad",
    caption = "Línea azul punteada: Aproximación discreta | Línea roja: Estimación Gibbs"
  )

comparacion_plot

```
El gráfico compara la densidad estimada de𝜃obtenida con el muestreador de Gibbs (línea roja) con la aproximación discreta teórica (línea azul punteada). Se observa que ambas curvas presentan picos en los mismos puntos, indicando que la cadena de Markov ha capturado correctamente la estructura de la distribución. La estimación de Gibbs es más suave, mientras que la aproximación discreta presenta oscilaciones mas pronunciadas.
:::

## Diagnósticos

### Pregunta 6

-   Usando las funciones indicadas en la p. 103 de @hoff2009a, representa la autocorrelación serial de los valores de $θ$ en la cadena y calcula el tamaño muestral efectivo de Monte Carlo.

*(NOTA: No olvides añadir el paquete `{coda}` en el entorno con el botón "renv" -\> "Snapshot Library...".)*

::: {#respuesta-6 .callout-note}
```{r preg-6}
# Cargar el paquete coda
library(coda)

# Convertir la cadena de Gibbs en un objeto mcmc
cadena_mcmc <- as.mcmc(cadena_Gibbs$theta)

# Representar la autocorrelación
autocorr.plot(cadena_mcmc)

# Calcular el tamaño muestral efectivo
effectiveSize(cadena_mcmc)

```

:::

### Pregunta 7

-   Define un objeto `cadena_Gibbs2`, de igual manera que definist `cadena_Gibbs`, y repite la pregunta 3, pero eligiendo un estado inicial en otro modo distinto. Después, genera una nueva cadena de Markov, almacenando sus estados en `cadena_Gibbs2` como en el ejercicio 4, y repite las representaciones y cálculos de los ejercicios 5 y 6.

::: {#respuesta-7 .callout-note}
```{r preg-7}
# Definir nueva cadena de Gibbs
cadena_Gibbs2 <- tibble(theta = numeric(N_GIBBS), delta = integer(N_GIBBS))

# Estado inicial en otro modo de la distribución
estado_cadena2 <- tibble(theta = -3, delta = 1)
cadena_Gibbs2[1, ] <- estado_cadena2

# Ejecutar el muestreador de Gibbs
for (i in 2:N_GIBBS) {
  cadena_Gibbs2[i, ] <- itera_Gibbs(cadena_Gibbs2$theta[i - 1], cadena_Gibbs2$delta[i - 1])
}

# Calcular la densidad de la nueva cadena
densidad_cadena2 <- density(cadena_Gibbs2$theta)

# Representar gráficamente la nueva distribución estimada
comparacion_plot2 <- ggplot() +
  geom_line(data = densidad, aes(x = theta, y = densidad), color = "blue", linetype = "dashed") + 
  geom_line(mapping = aes(x = densidad_cadena2$x, y = densidad_cadena2$y), color = "red") +
  labs(
    title = "Comparación de la distribución estimada con el segundo estado inicial",
    x = "θ",
    y = "Densidad",
    caption = "Línea azul punteada: Aproximación teórica | Línea roja: Gibbs con nuevo inicio"
  )

# Mostrar la gráfica
print(comparacion_plot2)

# Cargar paquete coda para análisis MCMC
library(coda)

# Convertir la nueva cadena de Gibbs a objeto MCMC
cadena_mcmc2 <- as.mcmc(cadena_Gibbs2$theta)

# Autocorrelación de la nueva cadena
autocorr.plot(cadena_mcmc2)

# Cálculo del tamaño muestral efectivo (ESS)
ess2 <- effectiveSize(cadena_mcmc2)
print(ess2)
```

:::

### Pregunta 8

**ATENCIÓN: El siguiente ejercicio NO está basado en la lectura; presta especial atención.**

-   Consulta la ayuda de la función `gelman.diag()` del paquete `{coda}`. Después, completa el siguiente chunk para calcular el estadístico $R$ (diagnóstico de Gelman-Rubin) para los valores de $θ$ a partir de las dos cadena de Markov que acabas de generar e interprétalo.

::: {#respuesta-8 .callout-note}
```{r calcular-diagnostico-GR}
theta_Gibbs <- list(
  theta_Gibbs_1 = cadena_Gibbs  |> pull(theta) |> as.mcmc(),
  theta_Gibbs_2 = cadena_Gibbs2 |> pull(theta) |> as.mcmc()
)
# Convertir a objeto mcmc.list
theta_mcmc_list <- mcmc.list(theta_Gibbs)

# Calcular el diagnóstico de Gelman-Rubin
gelman.diag(theta_mcmc_list)

```

:::

### Pregunta 9

-   De forma similar a como se ha hecho en la pregunta 7, obten dos cadenas de Markov de la distribución posterior conjunta de $p(θ, δ)$, pero con una longitud de 100,000 (ten paciencia, puede tardar un rato en hacer las iteraciones). Repite con estas dos nuevas cadenas los ejercicios 5, 6 y 8.

*(NOTA: Responde en el chunk de R proporcionado; la opción `#| cache: true` te ahorrará mucho tiempo de espera al renderizar el notebook después de hacerlo por primera vez.)*

::: {#respuesta-9 .callout-note}
```{r muestrear-Gibbs-100000}
#| cache: true # Guarda los resultados para no tener que ejecutar el "chunk"
               #   cada vez que se renderiza el notebook.

# Definir número de iteraciones más grande
N_GIBBS_LARGO <- 100000 

# Inicializar las dos cadenas de Gibbs
cadena_Gibbs_long1 <- tibble(theta = numeric(N_GIBBS_LARGO), delta = integer(N_GIBBS_LARGO))
cadena_Gibbs_long2 <- tibble(theta = numeric(N_GIBBS_LARGO), delta = integer(N_GIBBS_LARGO))

# Definir dos estados iniciales distintos
estado_cadena_long1 <- tibble(theta = -3, delta = 1) # Primer estado inicial
estado_cadena_long2 <- tibble(theta = 3, delta = 3)  # Segundo estado inicial

# Asignar estados iniciales a las cadenas
cadena_Gibbs_long1[1, ] <- estado_cadena_long1
cadena_Gibbs_long2[1, ] <- estado_cadena_long2

# Ejecutar el muestreador de Gibbs para la primera cadena
for (i in 2:N_GIBBS_LARGO) {
  cadena_Gibbs_long1[i, ] <- itera_Gibbs(cadena_Gibbs_long1$theta[i - 1], cadena_Gibbs_long1$delta[i - 1])
}

# Ejecutar el muestreador de Gibbs para la segunda cadena
for (i in 2:N_GIBBS_LARGO) {
  cadena_Gibbs_long2[i, ] <- itera_Gibbs(cadena_Gibbs_long2$theta[i - 1], cadena_Gibbs_long2$delta[i - 1])
}

# Estimar la densidad de las dos cadenas
densidad_cadena_long1 <- density(cadena_Gibbs_long1$theta)
densidad_cadena_long2 <- density(cadena_Gibbs_long2$theta)

# Representación gráfica de la comparación
comparacion_plot_long <- ggplot() +
  geom_line(data = densidad, aes(x = theta, y = densidad), color = "blue", linetype = "dashed") + 
  geom_line(mapping = aes(x = densidad_cadena_long1$x, y = densidad_cadena_long1$y), color = "red") +
  geom_line(mapping = aes(x = densidad_cadena_long2$x, y = densidad_cadena_long2$y), color = "green") +
  labs(
    title = "Distribuciones estimadas con 100,000 iteraciones",
    x = "θ",
    y = "Densidad",
    caption = "Línea azul punteada: Aproximación teórica | Línea roja: Gibbs (inicio -3) | Línea verde: Gibbs (inicio 3)"
  )

print(comparacion_plot_long)

# Evaluar autocorrelación
cadena_mcmc_long1 <- as.mcmc(cadena_Gibbs_long1$theta)
cadena_mcmc_long2 <- as.mcmc(cadena_Gibbs_long2$theta)

autocorr.plot(cadena_mcmc_long1)
autocorr.plot(cadena_mcmc_long2)

# Cálculo del tamaño muestral efectivo
ess_long1 <- effectiveSize(cadena_mcmc_long1)
ess_long2 <- effectiveSize(cadena_mcmc_long2)

print(ess_long1)
print(ess_long2)

# Diagnóstico de Gelman-Rubin
theta_Gibbs_long <- mcmc.list(cadena_mcmc_long1, cadena_mcmc_long2)
gelman_rubin_diag_long <- gelman.diag(theta_Gibbs_long)

print(gelman_rubin_diag_long)


```

:::

### Pregunta 10

-   La pregunta 8 demuestra el uso del estadístico de convergencia de Gelman-Rubin para cadenas de Markov, pero hace una serie de supuestos que no siempre se cumplen. En base a la ayuda de `gelman.diag()`, ¿cómo interpretarías los resultados del estadístico $R$ obtenidos en estos casos? ¿Qué crees que ocurriría si lo calculamos con dos (o más) cadenas que convergen "parcialmente" a uno de los modos de la distribución únicamente?

::: {#respuesta-10 .callout-note}
El estadístico de Gelman-Rubin evalúa la convergencia de múltiples cadenas de Markov comparando la variabilidad dentro de cada cadena con la variabilidad entre cadenas. Un valor cercano a 1 indica buena convergencia, mientras que valores significativamente mayores a 1.1 sugieren que las cadenas no han explorado completamente el espacio paramétrico. Si lo calculamos con cadenas que convergen solo a un modo de la distribución, podríamos obtener valores altos, indicando que las cadenas no han mezclado bien y que aún no han alcanzado la distribución estacionaria completa. En estos casos, sería necesario aumentar el número de iteraciones o mejorar la inicialización para garantizar una exploración adecuada de todos los modos posibles.

:::

## Distribución estacionaria

### Pregunta 11

-   Si crees que las cadenas en la pregunta 9 no han convergido satisfactoriamente a la distribución estacionaria, vuelve a ejecutarlas (quizá con mayor longitud) hasta obtener una convergencia sastisfactoria. Si consideras la convergencia de las cadenas satisfactoria (o una vez la consideres satisfactoria), colapsa los estados de ambas cadenas en un solo "data.frame" y obtén la densidad de $θ$ con las muestras de ambas cadenas.

::: {#respuesta-11 .callout-note}
Los resultados del estadístico de Gelman-Rubin muestran que el punto estimado es 1 y el límite superior de confianza es 1.01, lo que indica una muy buena convergencia. En general, valores cercanos a 1 sugieren que las cadenas han mezclado bien y han alcanzado la distribución estacionaria, por lo que parece que las cadenas de Markov generadas en la pregunta 9 son satisfactorias.

```{r preg-11}
# Unir ambas cadenas en un solo data.frame
cadena_Gibbs_comb <- bind_rows(cadena_Gibbs_long1, cadena_Gibbs_long2)

# Estimar la densidad con todas las muestras combinadas
densidad_comb <- density(cadena_Gibbs_comb$theta)

# Representación gráfica de la densidad combinada
comparacion_plot_comb <- ggplot() +
  geom_line(data = densidad, aes(x = theta, y = densidad), color = "blue", linetype = "dashed") + 
  geom_line(mapping = aes(x = densidad_comb$x, y = densidad_comb$y), color = "purple") +
  labs(
    title = "Densidad de θ con ambas cadenas combinadas",
    x = "θ",
    y = "Densidad",
    caption = "Línea azul punteada: Aproximación teórica | Línea púrpura: Gibbs (muestras combinadas)"
  )

# Mostrar la gráfica
print(comparacion_plot_comb)

```

:::

# Ejercicio 2: Ajuste de un modelo en Stan {#ejercicio-2}

Ahora que tienes una noción de qué es una cadena de Markov y cómo puede utilizarse para aproximar una distribución posterior, vamos a estimar un modelo Bayesiano relativamente complejo.
Hasta ahora hemos demostrado la aproximación a una distribución conocida mediante el método MCMC.
Sin embargo, recuerda que podemos aproximar cualquier distribución posterior gracias al algoritmo Metropolis-Hastings.
Esto incluye aquellas para las que no conocemos su "verosimilitud marginal" o "constante de proporcionalidad" [recuerda la "fórmula de la proporcionalidad en la [lectura del Tema 3](https://agora.uned.es/mod/resource/view.php?id=506207), @puza2015a, pp. 13-18].

Para estimar este modelo, vamos a utilizar el software [Stan](https://mc-stan.org/).
Stan es un software de análisis Bayesiano de datos que utiliza internamente un algoritmo MCMC para realizar la aproximación numérica de la distribución posterior de un modelo.

Verás que Stan obtiene muestras MCMC de manera muy rápida en comparación con el ejemplo que vimos en el Ejercicio 1.
Esto se debe a que "convierte" la especificación de un modelo a "código compilado" en C++ (en lugar de "traducir" el código línea a línea, como hace el intérprete de R).
Pero para ello, es necesario instalar las "herramientas de compilación" de R.
Así que antes de comenzar a usar Stan, asegúrate de tener instalada la versión de RTools correspondiente a tu sistema operativo, siguiendo las [instrucciones en el repositorio de Rstan en GitHub](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#configuring-c-toolchain).
Una vez hayas comprobado que Stan funciona, ejecutando el ejemplo según se indica en la sección [Verifying installation](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started#verifying-installation), continúa con el ejercicio.

## Regresión logística

En el [texto de ampliación del tema](https://agora.uned.es/mod/resource/view.php?id=514493) [@geyer2011, pp. 30-34] puedes ver un ejemplo de ajuste de un modelo de regresión logística Bayesiano, utilizando el paquete [`{mcmc}`](https://cran.r-project.org/package=mcmc) del propio autor.
Asegúrate de familiarizarte con el ejemplo, ya que lo utilizaremos en este ejercicio.

### Pregunta 12

-   Carga el dataset `logit` del paquete `{mcmc}`, explóralo, y explica su contenido.

*(NOTA: No olvides añadir el paquete `{mcmc}` al entorno.)*

::: {#respuesta-12 .callout-note}
```{r preg-12}
library(mcmc)
data(logit)

# Ver las primeras filas del dataset
head(logit)

# Resumen estadístico de las variables
summary(logit)

# Visualización rápida de la distribución de la variable respuesta
table(logit$y)

```
El dataset logit dentro del paquete MCMC contiene datos simulados para una regresión logística, donde y es la variable binaria de respuesta y x1, x2, x3, y x4 son predictores continuos. En el resumen, vemos que y toma valores de 0 y 1 con una distribución cercana al equilibrio (45 casos con y = 0 y 55 con y = 1). Las variables predictoras tienen medias cercanas a cero y están distribuidas dentro de un rango amplio, lo que sugiere que el dataset es adecuado para explorar la relación entre los predictores y la probabilidad de y = 1 en un modelo de regresión logística Bayesiano.
:::

### Pregunta 13

-   Utiliza el código proporcionado por el autor para ajustar el modelo lineal general con los datos y especificaciones del propio autor (p. 30) en un marco frecuentista. Comenta brevemente los resultados.

::: {#respuesta-13 .callout-note}
```{r preg-13}
data(logit)
out <- glm(y ~ x1 + x2 + x3 + x4, data = logit,
family = binomial(), x = TRUE)
summary(out)
```
El modelo de regresión logística ajustado con glm() muestra la relación entre la variable binaria y y los predictores x1, x2, x3, y x4. Los coeficientes estimados indican cómo cada predictor influye en la probabilidad de y = 1. x1 y x2 tienen efectos significativos (p < 0.05), especialmente x2 (p = 0.0021), lo que sugiere una fuerte asociación con la variable respuesta. x3 y x4 no alcanzan el nivel de significancia estándar, aunque x4 muestra cierta tendencia (p = 0.0817). La reducción de la deviacion residual frente a la deviacion nula sugiere que el modelo explica parte de la variabilidad en los datos, con un AIC de 97.67, lo que permite compararlo con otros modelos. 

:::

## Especificación en Stan

El [archivo "src/geyer_2011_logistic.stan"](src/geyer_2011_logistic.stan) contiene la sintaxis en Stan equivalente al modelo de regresión logística en @geyer2011 [pp. 31-32].

La sintaxis de R a continuación ejecuta el modelo usando el paquete [`{rstan}`](https://cran.r-project.org/package=rstan).
Consulta la [guía de usuario de Stan](https://mc-stan.org/docs/2_36/stan-users-guide/) para familiarizarte con esta sintaxis.

```{r ajustar-modelo-Stan}
#| cache: true

# Configuración de Stan para mejorar la eficiencia:
options(mc.cores = parallel::detectCores()) # Computación en paralelo
rstan_options(auto_write = TRUE)            # Escribe el modelo compilado

# Datos de entrada al modelo
datos_logit <- list(
  y = logit |> pull(y),
  x = logit |> select(starts_with('x')),
  N = nrow(logit),
  K = ncol(logit) - 1L
)

# Ajustar el modelo
fit_logit_stan <- stan(
  file   = "../src/geyer_2011_logistic.stan",
  iter   = 1000L,
  chains =    4L,
  data   = datos_logit
)
```

### Pregunta 14

-   Fíjate en la sección `data` (líneas 2-7) en el modelo de Stan. En base a esto, explica la estructura del objeto `datos_logit`.

::: {#respuesta-14 .callout-note}
El objeto datos_logit en R es una lista que contiene los datos necesarios para ajustar el modelo de regresión logística en Stan. Su estructura sigue la sección data del código Stan, asegurando que los datos estén correctamente organizados para el muestreo. La variable y almacena la respuesta binaria (0 o 1), mientras que x contiene las cuatro variables predictoras en formato matriz. Además, N representa el número total de observaciones en el conjunto de datos, y K indica la cantidad de predictores en el modelo.
:::

### Pregunta 15

-   Muestra el objeto `fit_logit_stan` y explica el significado del siguiente texto, de acuerdo a los términos que aparecen en las lecturas del tema:

    Inference for Stan model: anon_model.
    4 chains, each with iter=1000; warmup=500; thin=1; post-warmup draws per chain=500, total post-warmup draws=2000.

Explica también qué significan los valores e la columna `se_mean` y cómo se interpretan.

::: {#respuesta-15 .callout-note}
```{r preg-15}
fit_logit_stan
```
El resultado de fit_logit_stan muestra la configuración del muestreo en Stan, donde se han ejecutado cuatro cadenas de Markov con 1000 iteraciones cada una, de las cuales las primeras 500 se utilizaron para el calentamiento (warmup). Luego, se tomaron 500 muestras por cadena para la estimación, sumando un total de 2000 muestras posteriores al calentamiento. Este proceso garantiza que las cadenas exploren bien la distribución posterior, lo que permite obtener estimaciones confiables de los parámetros del modelo de regresión logística Bayesiano.

La columna se_mean representa el error estándar de la media estimada para cada parámetro y sugiere la estabilidad de la inferencia. Valores bajos de se_mean, como los obtenidos (~0.01), indican que la estimación de los coeficientes es precisa y que el muestreo ha sido eficiente. Además, el estadístico de Gelman-Rubin (Rhat ≈ 1) confirma que las cadenas han convergido bien, validando la calidad de la inferencia obtenida a partir del muestreo MCMC.
:::

### Pregunta 16

-   Explica cómo se diferencian las especificaciones del algoritmo en Stan anterior de las utilizadas por @geyer2011, en cuanto a número de cadenas, iteraciones, "burn-in", "thinning", y valores iniciales de las cadenas.

::: {#respuesta-16 .callout-note}
Las especificaciones del algoritmo en Stan difieren de las utilizadas por Geyer (2011) en varios aspectos clave. En Stan, el modelo se ejecuta con 4 cadenas, cada una con 1000 iteraciones, de las cuales 500 son de calentamiento (burn-in), asegurando que las muestras provengan de la distribución estacionaria. Además, no se aplica submuestreo (thinning), lo que significa que cada iteración posterior al calentamiento se almacena. En contraste, Geyer (2011) utiliza un enfoque más flexible, donde el número de iteraciones y el burn-in pueden ajustarse según la convergencia observada, y el thinning se emplea para reducir la autocorrelación en las muestras. También, en Stan, los valores iniciales de las cadenas suelen asignarse automáticamente o definirse explícitamente, mientras que en el enfoque de Geyer, la elección de los valores iniciales puede ser más estratégica para mejorar la exploración del espacio paramétrico.
:::

### Pregunta 17

-   ¿Podrías decir que las muestras del modelo aproximado con Stan representan adecuadamente la distribución posterior de los parámetros del modelo? ¿En qué te basas para afirmar / refutar que es así?

::: {#respuesta-17 .callout-note}
Sí, las muestras obtenidas con Stan representan adecuadamente la distribución posterior de los parámetros del modelo, basándonos en varios indicadores clave. Primero, el estadístico Rhat ≈ 1 en todos los parámetros sugiere que las cadenas han convergido correctamente, lo que significa que el muestreo ha explorado bien el espacio paramétrico. Además, el error estándar de la media (se_mean) es bajo, lo que indica estabilidad en las estimaciones. También, el número efectivo de muestras (n_eff) es alto, lo que confirma que el muestreo ha sido eficiente y que la autocorrelación entre iteraciones es baja.
:::

## Interpretación del modelo

### Pregunta 18

-   Compara los resultados de ajustar el modelo en Stan con los del modelo frecuentista en el objeto `out`. ¿Qué parámetro equivale a cada cuál, y cómo son los valores?

::: {#respuesta-18 .callout-note}
La comparación entre el modelo ajustado en Stan y el modelo frecuentista obtenido con glm() muestra diferencias en la estimación de los coeficientes. En ambos casos, los parámetros representan los mismos efectos de los predictores (x1, x2, x3, x4) sobre la variable binaria y, pero en Stan se realiza una inferencia Bayesiana, mientras que glm() sigue un enfoque máximo verosímil.

Los valores de los coeficientes en Stan (alpha para el intercepto y beta[1] a beta[4] para los predictores) son similares a los de glm(), pero presentan ligeras variaciones debido al uso de distribuciones previas y al muestreo Monte Carlo. Por ejemplo, el coeficiente de x2 en glm() es 1.114 con un error estándar de 0.363, mientras que en Stan el promedio posterior es 1.17 con una desviación estándar de 0.37, mostrando una ligera diferencia debida a la incorporación de incertidumbre en la estimación Bayesiana. Estas diferencias pueden ser útiles para obtener intervalos de credibilidad más interpretables que los intervalos de confianza del modelo frecuentista.
:::

### Pregunta 19

-   Utiliza el método `plot()` para representar el modelo Bayesiano aproximado con Stan e interprétalo. ¿Qué se está mostrando en esta representación?

*(NOTA: Este método devuelve un objeto de clase "ggplot", por lo que puedes usar cualquier función de `{ggplot2}` para dar formato y estilo a la salida gráfica si quieres.)*

::: {#respuesta-19 .callout-note}
```{r preg-19}
plot(fit_logit_stan)
```
La representación que has obtenido muestra las estimaciones de los parámetros del modelo Bayesiano ajustado en Stan, junto con sus intervalos de incertidumbre. En el gráfico aparecen los coeficientes alpha (intercepto) y beta[1] a beta[4] (efectos de los predictores), cada uno con su estimación puntual (marcada con un punto negro) y los intervalos de credibilidad, que reflejan la variabilidad en la inferencia.

Las líneas horizontales rojas representan los intervalos más concentrados (probablemente el 50% o el 80% de la distribución posterior), mientras que las líneas negras más largas indican el rango total de incertidumbre (por ejemplo, el intervalo de credibilidad del 95%). Esto permite visualizar cuánta incertidumbre hay en la estimación de cada parámetro, así como determinar cuáles tienen un efecto más claro en la regresión logística. Si los intervalos de credibilidad incluyen cero, significa que el parámetro podría no ser significativamente diferente de cero, lo que afectaría su interpretación en el modelo.
:::

### Pregunta 20

-   El paquete [`{bayesplot}`](https://cran.r-project.org/package=bayesplot) proporciona gran variedad de funciones construidas sobre `{ggplot2}` para representar cadenas de Markov, distribuciones posteriores, etc. a partir de la salida de Stan. Revisa la ayuda del paquete y averigua cómo representar el "trazado" de las cadenas de Markov y las distribuciones posteriores de los parámetros e interpreta las salidas.

::: {#respuesta-20 .callout-note}
```{r preg-20}
library(bayesplot)
mcmc_trace(as.array(fit_logit_stan), pars = c("alpha", "beta[1]", "beta[2]", "beta[3]", "beta[4]"))
mcmc_areas(as.array(fit_logit_stan), pars = c("alpha", "beta[1]", "beta[2]", "beta[3]", "beta[4]"), prob = 0.95)

```
La primera imagen muestra los trazados de las cadenas de Markov, donde cada línea representa la evolución de los parámetros (alpha, beta[1], beta[2], beta[3], beta[4]) a lo largo de las iteraciones del muestreo en Stan. La clave aquí es evaluar la mezcla de las cadenas, es decir, si las líneas están bien entrelazadas y sin tendencias sistemáticas. Si las trazas parecen estables y bien mezcladas, significa que las cadenas han alcanzado la distribución estacionaria y la inferencia es confiable. Si hubiera patrones o una mala mezcla, podríamos necesitar más iteraciones o ajustar los valores iniciales.

La segunda imagen presenta las distribuciones posteriores de los parámetros del modelo. En cada gráfico, la densidad posterior muestra la incertidumbre en la estimación de cada coeficiente, y las áreas sombreadas indican los intervalos de credibilidad, por ejemplo, el 95% de probabilidad de que el parámetro caiga dentro de ese rango. Si los intervalos son estrechos, significa que la estimación es precisa, mientras que intervalos amplios sugieren mayor incertidumbre. Además, si alguna distribución incluye cero, el predictor podría no ser estadísticamente relevante en el modelo.
:::

## Salidas adicionales en Stan

La función `mcmc::metrop()` admite un argumento `outfun`, el cual es a su vez una función.
@geyer2011 [p. 33] utiliza este argumento para llamar a una función que admite un vector (argumento `z`, y devuelve ese mismo vector, pero añadiendo también sus valores al cuadrado).
De esta manera, además de los parámetros del modelo, la función `mcmc::metrop()` devuelve también esos mismos parámetros al cuadrado.

Fíjate en la sección [`generated quantities`](https://mc-stan.org/docs/reference-manual/blocks.html#program-block-generated-quantities) del [archivo con el modelo de Stan](src/geyer_2011_logistic.stan).

### Pregunta 21

-   Añade a la sección `generated quantities` del modelo en Stan el código necesario para que genere un valor real llamado `alpha_2`, con el valor al cuadrado de `alpha`, y un vector llamado `beta_2` con los valores al cuadrado de `beta`. Ayúdate de la [referencia de Stan sobre funciones reales](https://mc-stan.org/docs/functions-reference/real-valued_basic_functions.html). Después ejecuta el modelo en Stan de nuevo y comprueba si la salida ha generado los nuevos valores correctamente. Representa las distribuciones de estos nuevos valores.

::: {#respuesta-21 .callout-note}

```{r preg-21-1}
cat(readLines("geyer_2011_logistic_local.stan"), sep = "\n")
```
```{r preg-21-2}
#| cache: true # Guarda los resultados para no tener que ejecutar el "chunk"
               #   cada vez que se renderiza el notebook.

# Configuración de Stan para mejorar eficiencia
options(mc.cores = parallel::detectCores())  # Computación en paralelo
rstan_options(auto_write = TRUE)  # Escribir el modelo compilado

# Definir los datos para el modelo
datos_logit <- list(
  y = logit |> pull(y),
  x = logit |> select(starts_with('x')),
  N = nrow(logit),
  K = ncol(logit) - 1L
)

# Ejecutar el modelo con Stan después de la modificación
fit_logit_stan_new <- stan(
  file = "geyer_2011_logistic_local.stan",
  iter = 1000L,
  chains = 4L,
  data = datos_logit
)

# Verificar que los nuevos valores han sido generados
print(fit_logit_stan_new, pars = c("alpha_2", "beta_2"))

# Visualización de las distribuciones posteriores de alpha_2 y beta_2
mcmc_areas(as.array(fit_logit_stan_new), pars = c("alpha_2", "beta_2[1]", "beta_2[2]", "beta_2[3]", "beta_2[4]"), prob = 0.95)

```

:::

# Referencias
